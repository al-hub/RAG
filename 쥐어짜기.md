## 응답성능 높이기
### KUnit 기반 단위테스트용 prompt
- KUnit : linux kernel 기반 단위 테스트
- 단위테스트 작성에 유리함 (귀찮은 것을 할 수 있음)
- 가우스에 코드 던지고 단위 테스트 작성하라고 하면 잘 됨
- 그런데 KUnit은 데이터가 부족함
  - 학습하지 않은 것도 해보자!! -> prompt engineering
  - TC 생성
  - TC 시나리오 다각화
### prompt engineering
- Prompt Engineering, RAG  | Fine-Tuning, Foundation Model
-         가성비
- RAG가 효율적이고 잠재력이 큼
- prompt engineering
  - 효과적인 communication을 된다.
  - 테크닉 : 지시문, 역할부여........
  - Zero-shot, One-shot, Few-shot 예제가 많을 수록 좋다.
  - Transformer (Self-Attention) -> 만들어진 원리를 이용해서 사용하자.
### 실재로 TC를 만들때 써보자.
- 각각에 맞게 prompt 를 작성하자.
- Testable 한 함수
  - 순수한 함수 (Pure Function) : Unit 테스트 용
  - Pure Function는 LLM에 만 던져도 된다.
- 실재로 하는 법 1. (영어가 유리), token 수제한에도 유리
  - **역할부여**
  - **예제넣기** (Template 또는 실재코드)
  - **지시문**
  - **테스트 대상 함수 제시**
  - 잘 됨!!
- 실재로 하는 법 2. Mock이 필요한 함수가 존재할 때
  - **역할부여** : 당신은 xxx 이다, 당신은 yyy에 대한 전문가이다. 나를 도와줘야한다.
  - **지시문**
  - **테스트 대상함수**
  - **예제** : Mock API 예제 제공 및 예제에 대한 추가설명
- 실재로 하는 법 3. 테스트가 불가능한 함수를 테스트가능하게 해서 만들기
  - 복잡하네... ㅎ
### LLM rest api 가 주어졌을 때,
- 아이디어
  - Tools For Building LLM Application
  - Langchaing : LLM app 개발에 사용되는 framework
  - LLM App with Langchain : 프롬프트 템플릿 작성, LLM 모델객체생성,  LLM model에 전달 (| 연산자 overload의 pipe)
  - 매우 간결하게 LLM app 을 구현할 수 있다.
  - Hugging Face Hub에 다양한 LLM 을 쓸 수 있다.
  - 런타임 소스코드 생성 및 실행 가능
  - LLM 실시간 정보를 가져오는 프로그램을 작성할 수 있다.
  - RAG 더 효과적으로 사용할 수 있다. (개발자가 미리 만들어 놓은 Vector Store에서 뽑을 수 있음)
    - Vector Store검색 + Retriever사용
    - Web Page 가져오기, 임베딩을 위해서 텍스트 분할(chunk size, over lap), vectorDB에 저장(가장 유사도가 높은 함수 적용)
  
### LLM 프로그래밍 특징
- 비결정론적 (핵심)
  - 원하는방향으로 제어필요 (통제하기)
  - 1. (API 호출전) 프롬프트 엔지니어링
  - 2. (API 호출후) 매개변수 값 조정
  - 3. (API 호출후) 트리밍
- 코드를 runtime 중에 작성하고, 사용할 수 있다.
  - 잘 예방할 수 있는 방법론 : LLM 프로그래밍을 위한 디자인 패턴
